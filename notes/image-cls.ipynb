{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/hirise:\n",
      "total 0\n",
      "-rw-r--r--   1 tg  staff    0 Apr 24 11:30 _VALID\n",
      "drwxr-xr-x  10 tg  staff  320 Apr 24 11:22 \u001B[1m\u001B[36mtest\u001B[m\u001B[m\n",
      "drwxr-xr-x  10 tg  staff  320 Apr 24 11:22 \u001B[1m\u001B[36mtrain\u001B[m\u001B[m\n",
      "drwxr-xr-x  10 tg  staff  320 Apr 24 11:29 \u001B[1m\u001B[36mval\u001B[m\u001B[m\n",
      "\n",
      "../data/msl:\n",
      "total 0\n",
      "-rw-r--r--   1 tg  staff    0 Apr 24 11:16 _VALID\n",
      "drwxr-xr-x  21 tg  staff  672 Apr 24 11:16 \u001B[1m\u001B[36mtest\u001B[m\u001B[m\n",
      "drwxr-xr-x  21 tg  staff  672 Apr 24 11:14 \u001B[1m\u001B[36mtrain\u001B[m\u001B[m\n",
      "drwxr-xr-x  21 tg  staff  672 Apr 24 11:16 \u001B[1m\u001B[36mval\u001B[m\u001B[m\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../data/{msl,hirise}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19\n"
     ]
    }
   ],
   "source": [
    "!ls -1 ../data/msl/train  | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import logging as log\n",
    "import json\n",
    "\n",
    "log.basicConfig(level=log.INFO)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Pretrained parent model: place this outside of child module to exclude from its graph \n",
    "\"\"\"\n",
    "class PreTrained:\n",
    "    \n",
    "    # lazy load\n",
    "    resnet = torchvision.models.resnext101_32x8d(pretrained=True)\n",
    "    resnet.eval()\n",
    "\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes, pre_classes=1000):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(pre_classes, n_classes)\n",
    "        \n",
    "    def forward(self, xs: Tensor):\n",
    "        feats = PreTrained.resnet(xs)\n",
    "        return self.fc(feats)\n",
    "\n",
    "model = ImageClassifier(n_classes=19)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.999), weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, work_dir:Path, data:Path, model: nn.Module, optim, device=device):\n",
    "        self.normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.train_transform = T.Compose([T.RandomResizedCrop(224),\n",
    "                              T.RandomHorizontalFlip(),\n",
    "                              T.ToTensor(), self.normalize])\n",
    "        self.eval_transform = T.Compose([T.Resize(256), T.CenterCrop(224),\n",
    "                             T.ToTensor(), self.normalize])\n",
    "        self.train_data = ImageFolder(data / 'train', transform=self.train_transform)\n",
    "        self.val_data = ImageFolder(data / 'val', transform=self.eval_transform)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.model = model.to(device)\n",
    "        self.optim = optim\n",
    "\n",
    "        work_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.work_dir = work_dir\n",
    "        self.models_dir = work_dir / 'models'\n",
    "        \n",
    "        self._state = dict(step=0, epoch=0, last_checkpt=None, train_loss=[], val_loss=[])\n",
    "        self._state_file = self.work_dir / 'state.json'\n",
    "        if self._state_file.exists():\n",
    "            self._state = json.loads(self._state_file.read_text())\n",
    "            log.info(f\"state={self._state}\")\n",
    "        \n",
    "        self.step = self._state['step']\n",
    "        self.epoch = self._state['epoch']\n",
    "        \n",
    "        \n",
    "    def _checkpt_name(self, step, train_loss, val_loss):\n",
    "        return f'model_{step:6d}_{train_loss:.5f}_{val_loss:.5f}.pkl'\n",
    "\n",
    "    def _checkpoint(self, train_metrics, val_loader) -> bool:\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            val_loss, val_acc = self.validate(val_loader)\n",
    "            train_loss = train_metrics['loss']\n",
    "            checkpt_path = self.models_dir / self._checkpt_name(self.step, train_loss, val_loss)\n",
    "            \n",
    "            state = dict(\n",
    "                model_state = self.model.state_dict(),\n",
    "                step = self.step,\n",
    "                epoch = self.epoch,\n",
    "                train_stats = train_metrics,\n",
    "                val_metrics = dict(loss=val_loss, accuracy=val_acc)\n",
    "            )\n",
    "            log.info(f\"Checkpoint {checkpt_path}\")\n",
    "            torch.save(state, checkpt_path)\n",
    "            #self.checkpoint(step=self.step, train_loss=train_loss)\n",
    "\n",
    "        self._state['val_loss'].append(val_loss)\n",
    "        self._state['train_loss'].append(train_loss)\n",
    "        \n",
    "    def validate(self, val_loader):\n",
    "         for xs, ys in val_loader:\n",
    "            pass\n",
    "\n",
    "    def train(self, max_step=10**6, max_epoch=10**3, batch_size=1,\n",
    "              num_threads=0, checkpoint=1000):\n",
    "        train_loader = DataLoader(self.train_data, batch_size=batch_size, shuffle=True,\n",
    "                                  num_workers=num_threads, pin_memory=True)\n",
    "        val_loader = DataLoader(self.val_data,batch_size=batch_size, shuffle=True,\n",
    "                                num_workers=num_threads, pin_memory=True)\n",
    "\n",
    "        \n",
    "        # todo resume these values from checkpoint\n",
    "        if self.step > 0:\n",
    "            log.info(f'resuming from step {self.step}; max_steps:{max_step}')\n",
    "\n",
    "        force_stop = False  # early stop when val metric goes up\n",
    "        while not force_stop and self.step <= max_step and self.epoch <= max_epoch:\n",
    "            train_losses = []\n",
    "            train_accs = []\n",
    "            for xs, ys in tqdm(train_loader): \n",
    "                self.step += 1\n",
    "                output = self.model(xs)\n",
    "                loss = self.criterion(output, ys)\n",
    "\n",
    "                train_losses.append(loss.item())\n",
    "                train_accs.append(accuracy(output.data, ys))\n",
    "                \n",
    "                  # compute gradient and do SGD step\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "                # \n",
    "                if self.step % checkpoint == 0:\n",
    "                    metrics = dict(loss=np.mean(train_losses), accuracy=np.mean(train_accs))\n",
    "                    force_stop = self._checkpoint(metrics, val_loader)\n",
    "                    train_losses.clear()\n",
    "                    train_accs.clear()\n",
    "                    break\n",
    "                if self.step > max_step:\n",
    "                    log.info(\"Max steps reached;\")\n",
    "                    break\n",
    "\n",
    "            if not force_stop and self.step < max_step:\n",
    "                self.epoch += 1        \n",
    "                \n",
    "def accuracy(output, target):\n",
    "    \"\"\"Computes accuracy\"\"\"\n",
    "    batch_size = target.size(0)\n",
    "    _, top_idx = output.max(dim=1)\n",
    "    correct = top_idx.eq(target).float().sum()\n",
    "    return 100.0 * correct/batch_size\n",
    "\n",
    "data = Path('../data/msl/')\n",
    "work = Path('../tmp.train')\n",
    "trainer = Trainer(data=data, work_dir=work, model=model, optim=optim)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:resuming from step 8; max_steps:1000000\n",
      "  0%|          | 16/5920 [00:41<4:15:26,  2.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-547e195ecd86>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-10-ebcfda3ba2d7>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, max_step, max_epoch, batch_size, num_threads, checkpoint)\u001B[0m\n\u001B[1;32m     82\u001B[0m                   \u001B[0;31m# compute gradient and do SGD step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m                 \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/rtg/lib/python3.7/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    243\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    244\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 245\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    246\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    247\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/rtg/lib/python3.7/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    145\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[1;32m    146\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001B[0m\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}